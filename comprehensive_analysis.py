import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_all_results():
    """Analyze all model results and create comprehensive comparison"""
    
    # Define your models and their result files (based on your file list)
    models = {
        'DeepSeek-v2 (16B)': {
            'trained': 'deepseek-v2_16b_trained_results.csv',
            'untrained': 'deepseek-v2_16b_untrained_results.csv'
        },
        'MedLLaMA2 (7B)': {
            'trained': 'medllama2_7b_trained_results.csv',
            'untrained': 'medllama2_7b_untrained_results.csv'
        },
        'Qwen3 (1.7B)': {
            'trained': 'qwen3_1.7b_trained_results.csv',
            'untrained': 'qwen3_1.7b_untrained_results.csv'
        },
        'ChatGPT 4o mini': {
            'trained': 'chatgpt_4o_mini_trained_results.csv',
            'untrained': 'chatgpt_4o_mini_untrained_results.csv'
        }
    }
    
    # Load reference file with your session ID
    reference_file = 'ai_comparison_test/comparison_test_5431_reference.csv'
    
    all_results = []
    
    try:
        # Load reference data to get true labels
        reference_df = pd.read_csv(reference_file)
        print(f"Loaded reference file with {len(reference_df)} samples")
        
        # Process all model results
        for model_name, files in models.items():
            for condition in ['trained', 'untrained']:
                try:
                    df = pd.read_csv(files[condition])
                    print(f"Processing {model_name} ({condition}) - {len(df)} samples")
                    
                    # Ensure we have the same number of samples as reference
                    if len(df) != len(reference_df):
                        print(f"Warning: {files[condition]} has {len(df)} samples, reference has {len(reference_df)}")
                        # Take the minimum length to avoid errors
                        min_len = min(len(df), len(reference_df))
                        df = df.head(min_len)
                        ref_subset = reference_df.head(min_len)
                    else:
                        ref_subset = reference_df
                    
                    # Convert to binary format
                    y_true = [1 if label == "Depressed" else 0 for label in ref_subset['true_label']]
                    y_pred = [1 if pred == "Depressed" else 0 for pred in df['ai_prediction']]
                    
                    # Calculate metrics
                    metrics = calculate_metrics(y_true, y_pred, f"{model_name} ({condition})")
                    metrics['model'] = model_name
                    metrics['condition'] = condition
                    metrics['model_size'] = extract_model_size(model_name)
                    metrics['deployment'] = 'Local' if model_name != 'ChatGPT 4o mini' else 'Cloud'
                    metrics['sample_count'] = len(y_true)
                    
                    all_results.append(metrics)
                    
                except FileNotFoundError:
                    print(f"Warning: File {files[condition]} not found")
                except Exception as e:
                    print(f"Error processing {files[condition]}: {e}")
        
    except FileNotFoundError:
        print(f"Error: Reference file {reference_file} not found")
        return None
    
    if not all_results:
        print("No results to analyze!")
        return None
    
    # Convert to DataFrame
    results_df = pd.DataFrame(all_results)
    
    # Save comprehensive results
    results_df.to_csv('comprehensive_model_comparison.csv', index=False)
    print(f"\nComprehensive results saved to 'comprehensive_model_comparison.csv'")
    
    # Create visualizations
    create_comprehensive_visualizations(results_df)
    
    # Print summary
    print_summary_analysis(results_df)
    
    # Create detailed comparison table
    create_detailed_comparison_table(results_df)
    
    return results_df

def calculate_metrics(y_true, y_pred, model_name):
    """Calculate performance metrics for a model"""
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    cm = confusion_matrix(y_true, y_pred)
    
    # Get confusion matrix values
    if cm.shape == (2, 2):
        tn, fp = cm[0]
        fn, tp = cm[1]
    else:
        # Handle edge cases where only one class is predicted
        tn, fp, fn, tp = 0, 0, 0, 0
        if len(np.unique(y_pred)) == 1:
            if y_pred[0] == 1:  # All predicted as positive
                tp = sum(y_true)
                fp = len(y_true) - sum(y_true)
            else:  # All predicted as negative
                tn = len(y_true) - sum(y_true)
                fn = sum(y_true)
    
    print(f"\n=== {model_name} ===")
    print(f"PrecizitÄte:  {accuracy:.4f}")
    print(f"PrecÄ«zums: {precision:.4f}")
    print(f"JÅ«tÄ«ba:    {recall:.4f}")
    print(f"F1 RezultÄts:  {f1:.4f}")
    print(f"Pareizi 'Suicidal' rezultÄti: {tp}, Nepareizi 'Suicidal' rezultÄti: {fp}")
    print(f"Pareizi 'Depressed' rezultÄti: {tn}, Nepareizi 'Depressed' rezultÄti: {fn}")
    print(f"Apjukuma matrica:\n{cm}")
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'true_positives': tp,
        'false_positives': fp,
        'true_negatives': tn,
        'false_negatives': fn
    }

def extract_model_size(model_name):
    """Extract model size from model name"""
    if '16B' in model_name:
        return '16B'
    elif '7B' in model_name:
        return '7B'
    elif '1.7B' in model_name:
        return '1.7B'
    elif 'ChatGPT' in model_name:
        return 'Unknown (Cloud)'
    else:
        return 'Unknown'

def create_comprehensive_visualizations(results_df):
    """Izveido visaptveroÅ¡as vizualizÄcijas modeÄ¼u veiktspÄ“jas analÄ«zei"""
    
    # UzstÄda grafiku stilu
    plt.style.use('default')
    sns.set_palette("husl")
    
    # 1. VeiktspÄ“jas salÄ«dzinÄjums pÄ“c apstÄkÄ¼iem (2x2 subplot)
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('ModeÄ¼u veiktspÄ“jas salÄ«dzinÄjums: ApmÄcÄ«ti vs NeapmÄcÄ«ti', fontsize=16, fontweight='bold')
    
    metrics = ['accuracy', 'precision', 'recall', 'f1']
    metric_labels = ['PrecizitÄte (Accuracy)', 'PrecÄ«zums (Precision)', 'JutÄ«ba (Recall)', 'F1 rezultÄts']
    colors = ['#4CAF50', '#FF7043']  # ZaÄ¼Å¡ un oranÅ¾s krÄsu kombinÄcija
    
    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):
        ax = axes[i//2, i%2]
        
        # PÄrveido datus Ä“rtÄkai attÄ“loÅ¡anai
        pivot_df = results_df.pivot(index='model', columns='condition', values=metric)
        
        # PÄrveido kolonnu nosaukumus latvieÅ¡u valodÄ
        if 'trained' in pivot_df.columns and 'untrained' in pivot_df.columns:
            pivot_df = pivot_df.rename(columns={'trained': 'ApmÄcÄ«ti', 'untrained': 'NeapmÄcÄ«ti'})
        
        # Izveido grupÄ“tu stabiÅ†u diagrammu
        pivot_df.plot(kind='bar', ax=ax, alpha=0.85, color=colors, width=0.75)
        ax.set_title(label, fontsize=13, fontweight='bold', pad=15)
        ax.set_ylabel('RezultÄts', fontsize=11)
        ax.set_xlabel('ModeÄ¼i', fontsize=11)
        ax.set_ylim(0, 1.05)
        ax.legend(title='ApmÄcÄ«bas stÄvoklis', title_fontsize=10, fontsize=9)
        ax.grid(axis='y', alpha=0.3, linestyle='--')
        ax.tick_params(axis='x', rotation=45, labelsize=9)
        ax.tick_params(axis='y', labelsize=9)
        
        # Pievieno vÄ“rtÄ«bu etiÄ·etes uz stabiÅ†iem
        for container in ax.containers:
            ax.bar_label(container, fmt='%.3f', fontsize=8, rotation=0, padding=3)
    
    plt.tight_layout()
    plt.savefig('modeÄ¼u_veiktspÄ“jas_salÄ«dzinÄjums.png', dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    print("âœ… SaglabÄts: modeÄ¼u_veiktspÄ“jas_salÄ«dzinÄjums.png")
    plt.show()
    
    # 2. ApmÄcÄ«bas uzlabojumu analÄ«ze (karstuma karte)
    improvement_data = []
    for model in results_df['model'].unique():
        model_data = results_df[results_df['model'] == model]
        if len(model_data) == 2:  # PastÄv gan apmÄcÄ«ti, gan neapmÄcÄ«ti dati
            trained = model_data[model_data['condition'] == 'trained'].iloc[0]
            untrained = model_data[model_data['condition'] == 'untrained'].iloc[0]
            
            for metric, label in zip(metrics, metric_labels):
                improvement = trained[metric] - untrained[metric]
                improvement_data.append({
                    'model': model,
                    'metric': label,
                    'improvement': improvement,
                    'improvement_percent': (improvement / untrained[metric] * 100) if untrained[metric] > 0 else 0
                })
    
    if improvement_data:
        improvement_df = pd.DataFrame(improvement_data)
        improvement_pivot = improvement_df.pivot(index='model', columns='metric', values='improvement')
        
        plt.figure(figsize=(14, 10))
        
        # Izveido karstuma karti ar uzlabotu krÄsu shÄ“mu
        heatmap = sns.heatmap(improvement_pivot, annot=True, cmap='RdYlBu_r', center=0, 
                    fmt='.3f', cbar_kws={'label': 'Uzlabojums (ApmÄcÄ«ti - NeapmÄcÄ«ti)'},
                    linewidths=0.8, linecolor='white', 
                    annot_kws={'fontsize': 10, 'fontweight': 'bold'})
        
        plt.title('ApmÄcÄ«bas ietekme uz modeÄ¼u veiktspÄ“ju', fontsize=18, fontweight='bold', pad=20)
        plt.xlabel('VeiktspÄ“jas rÄdÄ«tÄji', fontsize=14, fontweight='bold')
        plt.ylabel('ModeÄ¼i', fontsize=14, fontweight='bold')
        plt.xticks(rotation=15, fontsize=11)
        plt.yticks(rotation=0, fontsize=11)
        
        # Pievieno krÄsu skalu aprakstu
        cbar = heatmap.collections[0].colorbar
        cbar.set_label('Uzlabojums (pozitÄ«vs = labÄk)', fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('apmÄcÄ«bas_uzlabojumu_karte.png', dpi=300, bbox_inches='tight',
                    facecolor='white', edgecolor='none')
        print("âœ… SaglabÄts: apmÄcÄ«bas_uzlabojumu_karte.png")
        plt.show()
    
    # 3. LokÄlo vs MÄkoÅ†a modeÄ¼u salÄ«dzinÄjums
    if 'deployment' in results_df.columns:
        local_models = results_df[results_df['deployment'] == 'Local']
        cloud_models = results_df[results_df['deployment'] == 'Cloud']
        
        if not local_models.empty or not cloud_models.empty:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('LokÄlie vs MÄkoÅ†a modeÄ¼i: VeiktspÄ“jas salÄ«dzinÄjums', 
                        fontsize=16, fontweight='bold')
            
            deployment_colors = {
                'LokÄlie (ApmÄcÄ«ti)': '#2E7D32',      # TumÅ¡i zaÄ¼Å¡
                'LokÄlie (NeapmÄcÄ«ti)': '#81C784',    # GaiÅ¡i zaÄ¼Å¡  
                'MÄkoÅ†a (ApmÄcÄ«ti)': '#1565C0',       # TumÅ¡i zils
                'MÄkoÅ†a (NeapmÄcÄ«ti)': '#64B5F6'      # GaiÅ¡i zils
            }
            
            for i, (metric, label) in enumerate(zip(metrics, metric_labels)):
                ax = axes[i//2, i%2]
                
                x_pos = 0
                bar_width = 0.35
                
                # AttÄ“lo lokÄlos modeÄ¼us
                if not local_models.empty:
                    for j, condition in enumerate(['trained', 'untrained']):
                        subset = local_models[local_models['condition'] == condition]
                        if not subset.empty:
                            condition_lv = 'ApmÄcÄ«ti' if condition == 'trained' else 'NeapmÄcÄ«ti'
                            color_key = f'LokÄlie ({condition_lv})'
                            
                            bars = ax.bar([x_pos + j * bar_width], subset[metric].iloc[0], 
                                         width=bar_width, alpha=0.8, 
                                         color=deployment_colors[color_key],
                                         label=color_key)
                            
                            # Pievieno vÄ“rtÄ«bu uz stabiÅ†a
                            ax.bar_label(bars, fmt='%.3f', fontsize=9, fontweight='bold')
                
                # AttÄ“lo mÄkoÅ†a modeÄ¼us
                if not cloud_models.empty:
                    x_pos = 1.0
                    for j, condition in enumerate(['trained', 'untrained']):
                        subset = cloud_models[cloud_models['condition'] == condition]
                        if not subset.empty:
                            condition_lv = 'ApmÄcÄ«ti' if condition == 'trained' else 'NeapmÄcÄ«ti'
                            color_key = f'MÄkoÅ†a ({condition_lv})'
                            
                            bars = ax.bar([x_pos + j * bar_width], subset[metric].iloc[0], 
                                         width=bar_width, alpha=0.8,
                                         color=deployment_colors[color_key],
                                         label=color_key)
                            
                            # Pievieno vÄ“rtÄ«bu uz stabiÅ†a
                            ax.bar_label(bars, fmt='%.3f', fontsize=9, fontweight='bold')
                
                ax.set_xlabel('IzvietoÅ¡anas veids', fontsize=11)
                ax.set_ylabel(label.split(' ')[0], fontsize=11)
                ax.set_title(label, fontsize=12, fontweight='bold')
                ax.set_xticks([0.175, 1.175])
                ax.set_xticklabels(['LokÄlie modeÄ¼i', 'MÄkoÅ†a modeÄ¼i'])
                ax.legend(fontsize=8, loc='upper right')
                ax.grid(axis='y', alpha=0.3, linestyle='--')
                ax.set_ylim(0, 1.05)
            
            plt.tight_layout()
            plt.savefig('lokÄlie_vs_mÄkoÅ†a_salÄ«dzinÄjums.png', dpi=300, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            print("âœ… SaglabÄts: lokÄlie_vs_mÄkoÅ†a_salÄ«dzinÄjums.png")
            plt.show()
    
    # 4. ModeÄ¼a izmÄ“ra analÄ«ze (tikai lokÄlajiem modeÄ¼iem)
    # 4. ModeÄ¼a izmÄ“ra analÄ«ze (tikai lokÄlajiem modeÄ¼iem) - LABOTÄ€ VERSIJA
    if 'model_size' in results_df.columns and 'deployment' in results_df.columns:
        local_trained = results_df[(results_df['deployment'] == 'Local') & 
                                 (results_df['condition'] == 'trained')]
        
        if len(local_trained) > 1:
            fig, axes = plt.subplots(2, 2, figsize=(14, 10))
            fig.suptitle('ModeÄ¼a izmÄ“ra ietekme uz veiktspÄ“ju (LokÄlie apmÄcÄ«tie modeÄ¼i)', 
                        fontsize=16, fontweight='bold')
            
            # KartÄ“ modeÄ¼u izmÄ“rus uz skaitliskÄm vÄ“rtÄ«bÄm
            # LABOTS: Qwen3 ir 1.7B, nevis 7B
            size_mapping = {
                '1.7B': 1.7, 
                '3B': 3.0, 
                '7B': 7.0, 
                '13B': 13.0, 
                '16B': 16.0, 
                '32B': 32.0
            }
            
            # SpecifiskÄ kartÄ“Å¡ana modeÄ¼iem ar nepareiziem nosaukumiem
            model_size_corrections = {
                'Qwen3 (1.7B)': '1.7B',  # Qwen3 faktiski ir 1.7B parametri
                'MedLLaMA2 (7B)': '7B',  # Ja nepiecieÅ¡ams
            }
            
            for i, (metric, metric_label) in enumerate(zip(metrics, metric_labels)):
                ax = axes[i//2, i%2]
                
                model_sizes = []
                model_scores = []
                model_labels = []  # LABOTS: mainÄ«ts nosaukums, lai nebÅ«tu konflikts
                
                for _, row in local_trained.iterrows():
                    model_name = row['model']
                    stated_size = row['model_size']
                    
                    # Izmanto korekcijas, ja nepiecieÅ¡ams
                    if model_name in model_size_corrections:
                        actual_size = model_size_corrections[model_name]
                    else:
                        actual_size = stated_size
                    
                    if actual_size in size_mapping:
                        model_sizes.append(size_mapping[actual_size])
                        model_scores.append(row[metric])
                        
                        # Izveido skaidru etiÄ·eti
                        clean_model_name = model_name.split(' ')[0] if ' ' in model_name else model_name
                        model_labels.append(f"{clean_model_name}\n({actual_size})")
                
                if model_sizes and len(model_sizes) >= 2:
                    # Izveido punktu diagrammu
                    scatter = ax.scatter(model_sizes, model_scores, alpha=0.8, s=200, 
                                       c=range(len(model_sizes)), cmap='plasma', 
                                       edgecolors='black', linewidth=1.5)
                    
                    # Pievieno modeÄ¼u etiÄ·etes
                    for size, score, label_text in zip(model_sizes, model_scores, model_labels):
                        # Uzlabo etiÄ·etes pozicionÄ“Å¡anu
                        offset_x = 15 if size < 10 else -15  # MazÄkiem modeÄ¼iem pa labi, lielÄkiem pa kreisi
                        ha_align = 'left' if size < 10 else 'right'
                        
                        # Intelligent positioning to avoid title overlap
                        if score > 0.8:  # If point is high, place label below
                            offset_y = -25
                            va_align = 'top'
                        else:  # If point is lower, place label above
                            offset_y = 15
                            va_align = 'bottom'
                        
                        ax.annotate(label_text, (size, score), 
                                   xytext=(offset_x, offset_y), 
                                   textcoords='offset points', 
                                   fontsize=9,
                                   bbox=dict(boxstyle='round,pad=0.4', 
                                           facecolor='white', 
                                           alpha=0.9,
                                           edgecolor='gray'),
                                   ha=ha_align,
                                   va=va_align)
                    
                    # Pievieno tendences lÄ«niju
                    if len(model_sizes) >= 2:  # SamazinÄts no 3 uz 2, lai darbotos ar mazÄk punktiem
                        try:
                            z = np.polyfit(model_sizes, model_scores, 1)
                            p = np.poly1d(z)
                            x_trend = np.linspace(min(model_sizes), max(model_sizes), 100)
                            
                            # AprÄ“Ä·ina RÂ² vÄ“rtÄ«bu
                            correlation_matrix = np.corrcoef(model_sizes, model_scores)
                            r_squared = correlation_matrix[0,1]**2
                            
                            ax.plot(x_trend, p(x_trend), "r--", alpha=0.8, linewidth=2,
                                   label=f'Tendence (RÂ² = {r_squared:.3f})')
                            ax.legend(fontsize=9, loc='best')
                        except:
                            print(f"NevarÄ“ja aprÄ“Ä·inÄt tendences lÄ«niju metrikai: {metric}")
                
                # Uzlabo ass etiÄ·etes
                ax.set_xlabel('ModeÄ¼a izmÄ“rs (miljardi parametru)', fontsize=11, fontweight='bold')
                ax.set_ylabel(metric_label.split(' ')[0], fontsize=11, fontweight='bold')  # LABOTS: izmanto metric_label
                ax.set_title(metric_label, fontsize=12, fontweight='bold')
                ax.grid(True, alpha=0.3, linestyle='--')
                
                # Uzlabo ass iestatÄ«jumus
                if model_sizes:
                    ax.set_xscale('log')
                    ax.set_xlim(left=min(model_sizes)*0.7, right=max(model_sizes)*1.4)
                    
                    # UzstÄda x-ass etiÄ·etes
                    x_ticks = sorted(list(set(model_sizes)))
                    ax.set_xticks(x_ticks)
                    ax.set_xticklabels([f'{x:.1f}B' for x in x_ticks])
                
                ax.set_ylim(0, 1.05)
                
                # Pievieno papildu informÄciju, ja nav datu
                if not model_sizes:
                    ax.text(0.5, 0.5, 'Nav pieejami dati', 
                           ha='center', va='center', transform=ax.transAxes,
                           fontsize=12, alpha=0.6)
            
            plt.tight_layout()
            plt.savefig('modeÄ¼a_izmÄ“rs_vs_veiktspÄ“ja.png', dpi=300, bbox_inches='tight',
                       facecolor='white', edgecolor='none')
            print("âœ… SaglabÄts: modeÄ¼a_izmÄ“rs_vs_veiktspÄ“ja.png")
            plt.show()
            
            # Papildu debug informÄcija
            print("\nğŸ” DEBUG INFO - ModeÄ¼u izmÄ“ri:")
            for _, row in local_trained.iterrows():
                model_name = row['model']
                stated_size = row['model_size']
                corrected_size = model_size_corrections.get(model_name, stated_size)
                print(f"  â€¢ {model_name}: {stated_size} â†’ {corrected_size}")
    
    # 5. Kopsavilkuma tabula
    print("\n" + "="*80)
    print("ğŸ“Š MODEÄ»U VEIKTSPÄ’JAS KOPSAVILKUMS")
    print("="*80)
    
    # AprÄ“Ä·ina vidÄ“jos rÄdÄ«tÄjus
    summary_stats = results_df.groupby(['model', 'condition'])[metrics].mean()
    
    for model in results_df['model'].unique():
        print(f"\nğŸ”¹ {model.upper()}")
        print("-" * (len(model) + 4))
        
        model_data = results_df[results_df['model'] == model]
        
        for condition in ['trained', 'untrained']:
            condition_lv = "ApmÄcÄ«ts" if condition == 'trained' else "NeapmÄcÄ«ts"
            subset = model_data[model_data['condition'] == condition]
            
            if not subset.empty:
                print(f"  {condition_lv}:")
                for metric, label in zip(metrics, metric_labels):
                    value = subset[metric].iloc[0]
                    print(f"    â€¢ {label}: {value:.3f}")
        
        # AprÄ“Ä·ina uzlabojumu
        trained_data = model_data[model_data['condition'] == 'trained']
        untrained_data = model_data[model_data['condition'] == 'untrained']
        
        if not trained_data.empty and not untrained_data.empty:
            print("  ğŸ“ˆ Uzlabojums:")
            for metric, label in zip(metrics, metric_labels):
                improvement = trained_data[metric].iloc[0] - untrained_data[metric].iloc[0]
                improvement_pct = (improvement / untrained_data[metric].iloc[0] * 100) if untrained_data[metric].iloc[0] > 0 else 0
                print(f"    â€¢ {label}: {improvement:+.3f} ({improvement_pct:+.1f}%)")
    
    print("\n" + "="*80)
    print("âœ… Visi vizualizÄciju faili ir veiksmÄ«gi saglabÄti!")
    print("="*80)
    
def create_detailed_comparison_table(results_df):
    """Create a detailed comparison table"""
    
    # Create a formatted table for easy reading
    comparison_table = results_df.pivot_table(
        values=['accuracy', 'precision', 'recall', 'f1'], 
        index='model', 
        columns='condition',
        aggfunc='first'
    )
    
    # Round to 4 decimal places
    comparison_table = comparison_table.round(4)
    
    # Save to CSV
    comparison_table.to_csv('detailed_model_comparison_table.csv')
    print("Saved: detailed_model_comparison_table.csv")
    
    # Print formatted table
    print("\n" + "="*100)
    print(" DETALIZÄ’TA VEIKTSPÄ’JAS SALÄªDZINÄ€JUMA TABULA")
    print("="*100)
    print(comparison_table.to_string())

def print_summary_analysis(results_df):
    """Print key insights from the analysis"""
    print("\n" + "="*80)
    print(" REZULTÄ€TU KOPSAVILKUMS")
    print("="*80)
    
    # Overall statistics
    print(f"\nğŸ“Š DATU KOPAS PÄ€RSKATS:")
    if not results_df.empty:
        sample_count = results_df.iloc[0]['sample_count']
        print(f"  â€¢ KopÄ“jais testa paraugu skaits: {sample_count}")
        print(f"  â€¢ TestÄ“tie modeÄ¼i: {len(results_df['model'].unique())}")
        print(f"  â€¢ TestÄ“tie nosacÄ«jumi: {len(results_df['condition'].unique())}")
    
    trained_results = results_df[results_df['condition'] == 'trained']
    untrained_results = results_df[results_df['condition'] == 'untrained']
    
    if not trained_results.empty:
        print("\nğŸ† LABÄ€KIE MODEÄ»I (APMÄ€CÄªTI):")
        metric_names = {'accuracy': 'PrecizitÄte', 'f1': 'F1 rezultÄts', 
                       'precision': 'PrecÄ«zums', 'recall': 'JutÄ«ba'}
        for metric in ['accuracy', 'f1', 'precision', 'recall']:
            best_model = trained_results.loc[trained_results[metric].idxmax()]
            print(f"  â€¢ {metric_names[metric]}: {best_model['model']} ({best_model[metric]:.4f})")
    
    if not untrained_results.empty:
        print("\nğŸ† LABÄ€KIE MODEÄ»I (NEAPMÄ€CÄªTI):")
        for metric in ['accuracy', 'f1']:
            best_model = untrained_results.loc[untrained_results[metric].idxmax()]
            print(f"  â€¢ {metric_names[metric]}: {best_model['model']} ({best_model[metric]:.4f})")
    
    # Training improvement analysis
    print("\nğŸ“ˆ APMÄ€CÄªBAS UZLABOJUMU ANALÄªZE:")
    improvements = []
    for model in results_df['model'].unique():
        model_data = results_df[results_df['model'] == model]
        if len(model_data) == 2:
            trained = model_data[model_data['condition'] == 'trained'].iloc[0]
            untrained = model_data[model_data['condition'] == 'untrained'].iloc[0]
            
            f1_improvement = trained['f1'] - untrained['f1']
            accuracy_improvement = trained['accuracy'] - untrained['accuracy']
            improvements.append(f1_improvement)
            
            print(f"  â€¢ {model}:")
            print(f"    - F1 rezultÄts: {f1_improvement:+.4f}")
            print(f"    - PrecizitÄte: {accuracy_improvement:+.4f}")
    
    # Overall effectiveness
    if improvements:
        avg_improvement = np.mean(improvements)
        positive_improvements = sum(1 for x in improvements if x > 0)
        total_models = len(improvements)
        
        print(f"\nğŸ“Š KOPÄ’JÄ€ APMÄ€CÄªBAS EFEKTIVITÄ€TE:")
        print(f"  â€¢ VidÄ“jais F1 uzlabojums: {avg_improvement:+.4f}")
        print(f"  â€¢ UzlabojuÅ¡ies modeÄ¼i: {positive_improvements}/{total_models}")
        
        if avg_improvement > 0.02:
            print(f"  âœ… ApmÄcÄ«bas piemÄ“ri ir vispÄrÄ“ji efektÄ«vi")
        elif avg_improvement > -0.02:
            print(f"  âš ï¸  ApmÄcÄ«ba uzrÄda jauktos rezultÄtus")
        else:
            print(f"  âŒ ApmÄcÄ«ba var bÅ«t pretproduktÄ«va")
    
    # Local vs Cloud analysis
    local_results = results_df[results_df['deployment'] == 'Local']
    cloud_results = results_df[results_df['deployment'] == 'Cloud']
    
    if not local_results.empty and not cloud_results.empty:
        print(f"\nğŸ¢ LOKÄ€LÄ€ un MÄ€KOÅ…A MODEÄ»U ANALÄªZE:")
        
        # Compare best performers
        best_local_f1 = local_results['f1'].max()
        best_cloud_f1 = cloud_results['f1'].max()
        best_local_model = local_results.loc[local_results['f1'].idxmax(), 'model']
        best_cloud_model = cloud_results.loc[cloud_results['f1'].idxmax(), 'model']
        
        print(f"  â€¢ LabÄkais lokÄlais modelis: {best_local_model} (F1: {best_local_f1:.4f})")
        print(f"  â€¢ LabÄkais mÄkoÅ†a modelis: {best_cloud_model} (F1: {best_cloud_f1:.4f})")
        
        if best_local_f1 > best_cloud_f1:
            print(f"  âœ… LokÄlie modeÄ¼i var konkurÄ“t ar mÄkoÅ†a modeÄ¼iem")
        else:
            print(f"  ğŸ“¡ MÄkoÅ†a modeÄ¼i pÄrspÄ“j lokÄlos modeÄ¼us")
            print(f"  ğŸ’¡ Apsveriet privÄtuma un veiktspÄ“jas kompromisus")
    
    # Model size insights (for local models)
    local_trained = results_df[(results_df['deployment'] == 'Local') & (results_df['condition'] == 'trained')]
    if len(local_trained) > 1:
        print(f"\nğŸ“ MODEÄ»A IZMÄ’RA ANALÄªZE (LOKÄ€LIE MODEÄ»I):")
        
        # Sort by model size
        size_order = {'1.7B': 1, '7B': 2, '16B': 3}
        local_trained_sorted = local_trained.copy()
        local_trained_sorted['size_order'] = local_trained_sorted['model_size'].map(size_order)
        local_trained_sorted = local_trained_sorted.sort_values('size_order')
        
        print("  â€¢ VeiktspÄ“ja pÄ“c modeÄ¼a izmÄ“ra:")
        for _, row in local_trained_sorted.iterrows():
            print(f"    - {row['model']} ({row['model_size']}): F1 = {row['f1']:.4f}")
        
        # Check if larger models perform better
        f1_scores = local_trained_sorted['f1'].tolist()
        if len(f1_scores) >= 3:
            if f1_scores[-1] > f1_scores[0]:  # Largest vs smallest
                print(f"  ğŸ“ˆ LielÄki modeÄ¼i parasti darbojas labÄk")
            else:
                print(f"  ğŸ¤” IzmÄ“rs negarantÄ“ labÄku veiktspÄ“ju")
    
    # Key recommendations
    print(f"\nğŸ’¡ GALVENÄ€S ATZINÄªBAS PROMOCIJAS DARBÄ€:")
    print(f"  1. SalÄ«dzinÄt apmÄcÄ«bas efektivitÄti daÅ¾ÄdÄs modeÄ¼u arhitektÅ«rÄs")
    print(f"  2. AnalizÄ“t privÄtuma un veiktspÄ“jas kompromisu starp lokÄlajiem un mÄkoÅ†a modeÄ¼iem")
    print(f"  3. PÄrbaudÄ«t, vai modeÄ¼a izmÄ“rs korelÄ“ ar depresijas noteikÅ¡anas precizitÄti")
    print(f"  4. ApsvÄ“rt viltus pozitÄ«vu un viltus negatÄ«vu rezultÄtu praktiskÄs sekas")
    print(f"  5. Apspriest neobjektivitÄti depresijas klasifikÄcijÄ lielÄkajÄ daÄ¼Ä modeÄ¼u")

if __name__ == "__main__":
    print("SÄk visaptveroÅ¡u visu modeÄ¼u rezultÄtu analÄ«zi...")
    print("MeklÄ“ju failus:")
    print("- deepseek-v2_16b_trained_results.csv")
    print("- deepseek-v2_16b_untrained_results.csv")
    print("- medllama2_7b_trained_results.csv")
    print("- medllama2_7b_untrained_results.csv")
    print("- qwen3_1.7b_trained_results.csv")
    print("- qwen3_1.7b_untrained_results.csv")
    print("- chatgpt_4o_mini_trained_results.csv")
    print("- chatgpt_4o_mini_untrained_results.csv")
    print("- ai_comparison_test/comparison_test_5431_reference.csv")
    print("\n" + "="*50)
    
    results_df = analyze_all_results()
    
    if results_df is not None:
        print(f"\nâœ… AnalÄ«ze pabeigta!")
        print(f"ğŸ“Š RezultÄti saglabÄti 'comprehensive_model_comparison.csv'")
        print(f"ğŸ“ˆ VizualizÄcijas saglabÄtas kÄ PNG faili")
        print(f"ğŸ“‹ DetalizÄ“ta salÄ«dzinÄÅ¡anas tabula saglabÄta failÄ 'detailed_model_comparison_table.csv'")
        print(f"ğŸ“‹ Skatiet iepriekÅ¡ minÄ“to kopsavilkumu, lai iegÅ«tu galveno informÄciju")
    else:
        print(f"\nâŒ AnalÄ«ze neizdevÄs â€” pÄrbaudiet failu ceÄ¼us un formÄtus")